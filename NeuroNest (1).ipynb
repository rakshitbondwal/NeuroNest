{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70_qt6g7v0if"
      },
      "outputs": [],
      "source": [
        "# Upload CSV from your computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['Parkinsson_speech_dataset (1).csv']))"
      ],
      "metadata": {
        "id": "40w9TKSdxI6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded[\"Parkinsson_speech_dataset (1).csv\"]))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kweYkxdhxqhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PreProcess The Data**"
      ],
      "metadata": {
        "id": "diUfjq8YxyEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "1P6KLyM7x26B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary identifier columns\n",
        "df = df.drop(columns=['id'], errors='ignore')\n",
        "\n",
        "# Split features (X) and labels (y)\n",
        "X = df.drop(columns=['class'])  # Features\n",
        "y = df['class']  # Labels (1 = Parkinson's, 0 = Healthy)\n",
        "\n",
        "# Normalize the features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"âœ… Features shape:\", X_scaled.shape)\n",
        "print(\"âœ… Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "id": "u5cHG1TpyVym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train-Test Split & Model Training**"
      ],
      "metadata": {
        "id": "0jVyLoxVygac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nðŸ” Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nðŸ“Š Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "_1iNgLHhydf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the Model for later use**"
      ],
      "metadata": {
        "id": "ZqEk2uAgy6wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save model and scaler\n",
        "joblib.dump(model, 'parkinsons_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "print(\"âœ… Model and scaler saved successfully.\")\n"
      ],
      "metadata": {
        "id": "JDIprFC2y-vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Rc6KT3rTOo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ezHBCWieTQS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "ZvJWGQoGDJE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Extract the uploaded file\n",
        "with zipfile.ZipFile(\"EYE DATASET ZIPPED.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"mrlEyes_2018\")\n",
        "\n",
        "print(\"âœ… Dataset extracted successfully.\")\n"
      ],
      "metadata": {
        "id": "9GgoHPQiK3f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing Code**"
      ],
      "metadata": {
        "id": "BrVjMfnLL5LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all subdirectories in current working dir\n",
        "for folder in os.listdir():\n",
        "    print(folder)"
      ],
      "metadata": {
        "id": "b3ddTBJwMlYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Show a few .png image filenames to confirm label pattern\n",
        "sample_files = []\n",
        "for root, dirs, files in os.walk(\"mrlEyes_2018\"):\n",
        "    for file in files:\n",
        "        if file.endswith(\".png\"):\n",
        "            sample_files.append(os.path.join(root, file))\n",
        "        if len(sample_files) >= 10:\n",
        "            break\n",
        "\n",
        "print(\"ðŸ” Sample image file paths:\")\n",
        "for f in sample_files:\n",
        "    print(f)\n"
      ],
      "metadata": {
        "id": "YE5F_mLfMw9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "IMG_SIZE = 24\n",
        "dataset_path = \"mrlEyes_2018/data\"\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".png\"):\n",
        "            filepath = os.path.join(root, file)\n",
        "\n",
        "            # Label from folder name\n",
        "            if \"sleepy\" in root.lower():\n",
        "                label = 0  # Closed\n",
        "            elif \"awake\" in root.lower():\n",
        "                label = 1  # Open\n",
        "            else:\n",
        "                print(\"âŒ Unknown label folder:\", root)\n",
        "                continue\n",
        "\n",
        "            img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            data.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "print(\"âœ… Total images loaded:\", len(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl39oYUpLycR",
        "outputId": "82ab6e04-2acf-43c3-8adb-fc53a707152c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Total images loaded: 84898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = np.array(data).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0\n",
        "labels = np.array(labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "q54oNAqjNsYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train an Eye State Detection Model **"
      ],
      "metadata": {
        "id": "pHojcpk8N65s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ],
      "metadata": {
        "id": "60P7cOuBN3mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n"
      ],
      "metadata": {
        "id": "88ajhki8N_vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "4mnCsJKkOEOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    validation_data=(X_test, y_test)\n",
        "                    )\n"
      ],
      "metadata": {
        "id": "86oU-tHgOGVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "XwCANCBlwKaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('eye_state_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1wKywFhyF4N",
        "outputId": "37d30af0-3644-4d66-efe5-6542fece6c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = tf.keras.models.load_model('eye_state_model.h5')\n",
        "\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Set image size (replace this with the actual IMG_SIZE you used during training, e.g., 24)\n",
        "IMG_SIZE = 24\n",
        "\n",
        "while True:\n",
        "    # Read frame from webcam\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Failed to capture image\")\n",
        "        break\n",
        "\n",
        "    # Preprocess frame\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    resized_frame = cv2.resize(gray_frame, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
        "    reshaped_frame = resized_frame.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(reshaped_frame)\n",
        "\n",
        "    # Show prediction on the frame\n",
        "    label = \"Open Eye\" if prediction > 0.5 else \"Closed Eye\"\n",
        "    color = (0, 255, 0) if prediction > 0.5 else (0, 0, 255)\n",
        "\n",
        "    # Display text on the frame\n",
        "    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    # Optionally draw a bounding box (for demonstration)\n",
        "    cv2.rectangle(frame, (50, 50), (300, 300), color, 2)  # Modify coordinates based on detection\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('Eye State Detection', frame)\n",
        "\n",
        "    # Exit loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "sMRgmBS6wM7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('eye_state_model.h5')\n"
      ],
      "metadata": {
        "id": "xhH9q1DWwMph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the pre-trained model (ensure the model path is correct)\n",
        "model = tf.keras.models.load_model('eye_state_model.h5')\n",
        "\n",
        "# Define image size\n",
        "IMG_SIZE = 64  # Adjust as per your model input size\n",
        "\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()  # Capture each frame\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess frame\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    resized_frame = cv2.resize(gray_frame, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
        "    reshaped_frame = resized_frame.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "    # Predict eye state\n",
        "    prediction = model.predict(reshaped_frame)\n",
        "\n",
        "    # Check if the eye is open or closed\n",
        "    label = \"Open Eye\" if prediction > 0.5 else \"Closed Eye\"\n",
        "\n",
        "    # Display the prediction on the frame\n",
        "    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Show the frame\n",
        "    cv2.imshow(\"Eye State Detection\", frame)\n",
        "\n",
        "    # Break the loop on pressing 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "kIWlU6yZykFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flask opencv-python tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F07D0XGFy2Ha",
        "outputId": "ea75b35c-b92f-4659-828e-ccfeea6c48bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, Response\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = tf.keras.models.load_model('eye_state_model.h5')\n",
        "\n",
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Define image size for preprocessing\n",
        "IMG_SIZE = 64  # Adjust as per your model input size\n",
        "\n",
        "# Video streaming function\n",
        "def gen_frames():\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Preprocess the frame\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        resized_frame = cv2.resize(gray_frame, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
        "        reshaped_frame = resized_frame.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "        # Predict eye state\n",
        "        prediction = model.predict(reshaped_frame)\n",
        "        label = \"Open Eye\" if prediction > 0.5 else \"Closed Eye\"\n",
        "\n",
        "        # Draw prediction label on the frame\n",
        "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Encode the frame to send to frontend\n",
        "        ret, buffer = cv2.imencode('.jpg', frame)\n",
        "        frame = buffer.tobytes()\n",
        "\n",
        "        yield (b'--frame\\r\\n'\n",
        "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "4BNNlMKRy3uf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}